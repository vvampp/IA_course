{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1981a106-8e05-488e-9456-9b4c6d8f511b",
   "metadata": {},
   "source": [
    "# Práctica 6: Clasificadores de Distancia y Bayesianos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bee180-bf5a-4896-9f12-7616ed5acda5",
   "metadata": {},
   "source": [
    "## Intrucciones:\n",
    "1. Selecciona un dataset y realiza el pre-procesamiento que consideres conveniente.\n",
    "2. Aplica los siguientes modelos de clasificación:\n",
    "    - 1NN\n",
    "    - KNN con K={3,5,7,9}\n",
    "    - Naive Bayes\n",
    "3. Con los métodos de validación:\n",
    "    - Hold-out 70/30\n",
    "    - 10-Fold Cross-Validation\n",
    "    - Leave-One-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9ab4df-b6eb-4d3d-8020-55d01537334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, cross_validate\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix,\n",
    "                             classification_report, matthews_corrcoef, \n",
    "                             cohen_kappa_score, balanced_accuracy_score,\n",
    "                             make_scorer)\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bf346e-08f9-45c5-9cc2-035d8161be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    '1NN': KNeighborsClassifier(n_neighbors=1),\n",
    "    '3NN': KNeighborsClassifier(n_neighbors=3),\n",
    "    '5NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    '7NN': KNeighborsClassifier(n_neighbors=7),\n",
    "    '9NN': KNeighborsClassifier(n_neighbors=9),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5b30e5-b691-4ae5-8245-f354dca4abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_proba=None):\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Balanced Accuracy': balanced_accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'F1-Score': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "        'Cohen Kappa': cohen_kappa_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                metrics['ROC-AUC'] = roc_auc_score(y_true, y_proba[:, 1])\n",
    "            else:\n",
    "                metrics['ROC-AUC'] = roc_auc_score(y_true, y_proba, \n",
    "                                                   average='weighted', \n",
    "                                                   multi_class='ovr')\n",
    "        except:\n",
    "            metrics['ROC-AUC'] = np.nan\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3db416-ab6c-44a9-8b74-8532e639ae5d",
   "metadata": {},
   "source": [
    "## Predictive Mainteinance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a8d18-743f-4acb-b960-b7f590895cf1",
   "metadata": {},
   "source": [
    "Se importan los datasets pre procesados y serializados como archivos joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cfc3c70-ffec-4ed2-ad75-2ac0324b47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mainteinance_filepath = 'datasets/mainteinance/X_mainteinanceDataset.joblib'\n",
    "y_mainteinance_filepath = 'datasets/mainteinance/y_mainteinanceDataset.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06a140aa-5c4d-4ab0-82a0-3a20356e1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_m = load(X_mainteinance_filepath)\n",
    "y_m = load(y_mainteinance_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d491ec-ebd9-43fb-b5c2-c82e505e063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9976 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   air_temperature      9976 non-null   float64\n",
      " 1   process_temperature  9976 non-null   float64\n",
      " 2   rotational_speed     9976 non-null   float64\n",
      " 3   torque               9976 non-null   float64\n",
      " 4   tool_wear            9976 non-null   float64\n",
      " 5   L                    9976 non-null   float64\n",
      " 6   M                    9976 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 623.5 KB\n",
      "None\n",
      "[0 3 5 2 4 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_m.info())\n",
    "print(y_m.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34b544-38f5-4ff5-9a3c-1e316cc26e12",
   "metadata": {},
   "source": [
    "## HOLD-OUT 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53911786-a26d-4fb9-9267-5e2a57f643c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1NN:\n",
      "  Accuracy_m:          0.9642\n",
      "  Balanced Accuracy_m: 0.4573\n",
      "  Precision:         0.9642\n",
      "  Recall:            0.9642\n",
      "  F1-Score:          0.9640\n",
      "  MCC:               0.4169\n",
      "  Cohen Kappa:       0.4165\n",
      "  ROC-AUC:           0.6978\n",
      "  Confusion Matrix:\n",
      "[[2846   17    6    7    7   13]\n",
      " [  17   15    0    0    0    0]\n",
      " [  11    0   12    0    0    0]\n",
      " [  14    0    0   10    0    0]\n",
      " [   4    0    0    0    1    0]\n",
      " [  11    0    0    0    0    2]]\n",
      "\n",
      "3NN:\n",
      "  Accuracy_m:          0.9709\n",
      "  Balanced Accuracy_m: 0.3090\n",
      "  Precision:         0.9620\n",
      "  Recall:            0.9709\n",
      "  F1-Score:          0.9637\n",
      "  MCC:               0.3761\n",
      "  Cohen Kappa:       0.3287\n",
      "  ROC-AUC:           0.7965\n",
      "  Confusion Matrix:\n",
      "[[2884    7    3    0    0    2]\n",
      " [  25    7    0    0    0    0]\n",
      " [  15    0    8    0    0    0]\n",
      " [  17    0    0    7    0    0]\n",
      " [   5    0    0    0    0    0]\n",
      " [  13    0    0    0    0    0]]\n",
      "\n",
      "5NN:\n",
      "  Accuracy_m:          0.9726\n",
      "  Balanced Accuracy_m: 0.2834\n",
      "  Precision:         0.9625\n",
      "  Recall:            0.9726\n",
      "  F1-Score:          0.9634\n",
      "  MCC:               0.3973\n",
      "  Cohen Kappa:       0.3112\n",
      "  ROC-AUC:           0.8188\n",
      "  Confusion Matrix:\n",
      "[[2892    0    3    1    0    0]\n",
      " [  22   10    0    0    0    0]\n",
      " [  15    0    8    0    0    0]\n",
      " [  23    0    0    1    0    0]\n",
      " [   5    0    0    0    0    0]\n",
      " [  13    0    0    0    0    0]]\n",
      "\n",
      "7NN:\n",
      "  Accuracy_m:          0.9713\n",
      "  Balanced Accuracy_m: 0.2393\n",
      "  Precision:         0.9571\n",
      "  Recall:            0.9713\n",
      "  F1-Score:          0.9599\n",
      "  MCC:               0.3342\n",
      "  Cohen Kappa:       0.2143\n",
      "  ROC-AUC:           0.8360\n",
      "  Confusion Matrix:\n",
      "[[2895    0    1    0    0    0]\n",
      " [  25    7    0    0    0    0]\n",
      " [  18    0    5    0    0    0]\n",
      " [  24    0    0    0    0    0]\n",
      " [   5    0    0    0    0    0]\n",
      " [  13    0    0    0    0    0]]\n",
      "\n",
      "9NN:\n",
      "  Accuracy_m:          0.9703\n",
      "  Balanced Accuracy_m: 0.2268\n",
      "  Precision:         0.9547\n",
      "  Recall:            0.9703\n",
      "  F1-Score:          0.9584\n",
      "  MCC:               0.2891\n",
      "  Cohen Kappa:       0.1797\n",
      "  ROC-AUC:           0.8595\n",
      "  Confusion Matrix:\n",
      "[[2894    1    1    0    0    0]\n",
      " [  26    6    0    0    0    0]\n",
      " [  19    0    4    0    0    0]\n",
      " [  24    0    0    0    0    0]\n",
      " [   5    0    0    0    0    0]\n",
      " [  13    0    0    0    0    0]]\n",
      "\n",
      "Naive Bayes:\n",
      "  Accuracy_m:          0.9616\n",
      "  Balanced Accuracy_m: 0.4104\n",
      "  Precision:         0.9566\n",
      "  Recall:            0.9616\n",
      "  F1-Score:          0.9582\n",
      "  MCC:               0.4042\n",
      "  Cohen Kappa:       0.4036\n",
      "  ROC-AUC:           0.9334\n",
      "  Confusion Matrix:\n",
      "[[2838   34   23    1    0    0]\n",
      " [  11   21    0    0    0    0]\n",
      " [   4    0   19    0    0    0]\n",
      " [  23    1    0    0    0    0]\n",
      " [   4    1    0    0    0    0]\n",
      " [  13    0    0    0    0    0]]\n",
      " Accuracy  Balanced Accuracy  Precision   Recall  F1-Score      MCC  Cohen Kappa  ROC-AUC       Model\n",
      " 0.964250           0.457289   0.964232 0.964250  0.964037 0.416869     0.416537 0.697773         1NN\n",
      " 0.970932           0.309017   0.962019 0.970932  0.963705 0.376107     0.328699 0.796468         3NN\n",
      " 0.972603           0.283435   0.962469 0.972603  0.963390 0.397283     0.311197 0.818794         5NN\n",
      " 0.971266           0.239299   0.957087 0.971266  0.959917 0.334227     0.214309 0.836027         7NN\n",
      " 0.970264           0.226787   0.954664 0.970264  0.958423 0.289116     0.179707 0.859545         9NN\n",
      " 0.961577           0.410385   0.956611 0.961577  0.958242 0.404220     0.403585 0.933391 Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "X_m_train, X_m_test, y_m_train, y_m_test = train_test_split(X_m, y_m, test_size=0.3, \n",
    "                                                    random_state=42, stratify=y_m)\n",
    "\n",
    "results_holdout = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_m_train, y_m_train)\n",
    "    y_m_pred = model.predict(X_m_test)\n",
    "    y_m_proba = model.predict_proba(X_m_test) if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    metrics = evaluate_model(y_m_test, y_m_pred, y_m_proba)\n",
    "    metrics['Model'] = name\n",
    "    results_holdout.append(metrics)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy_m:          {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"  Balanced Accuracy_m: {metrics['Balanced Accuracy']:.4f}\")\n",
    "    print(f\"  Precision:         {metrics['Precision']:.4f}\")\n",
    "    print(f\"  Recall:            {metrics['Recall']:.4f}\")\n",
    "    print(f\"  F1-Score:          {metrics['F1-Score']:.4f}\")\n",
    "    print(f\"  MCC:               {metrics['MCC']:.4f}\")\n",
    "    print(f\"  Cohen Kappa:       {metrics['Cohen Kappa']:.4f}\")\n",
    "    if 'ROC-AUC' in metrics and not np.isnan(metrics['ROC-AUC']):\n",
    "        print(f\"  ROC-AUC:           {metrics['ROC-AUC']:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_m_test, y_m_pred)\n",
    "    print(f\"  Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "df_holdout = pd.DataFrame(results_holdout)\n",
    "print(df_holdout.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593eee2-3ed3-4065-a88a-5657460aedb0",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "**Balanced accuracy baja: debido al desbalance de clases**\n",
    "\n",
    "**Mejor modelo: 5NN**\n",
    "- 97.6% acc\n",
    "- Balance entre métricas generales\n",
    "- 0.8188 ROC-AUC (moderado - bueno)\n",
    "\n",
    "**Mejor ROC-AUC Naive Bayes**\n",
    "\n",
    "**Modelos KNN con K alto predicen la clase mayoritaria**\n",
    "**Modelos KNN ocn K bajo predicen minorías pero son inestables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c29d7-34ef-4d1f-bd9e-ddab6f074d5c",
   "metadata": {},
   "source": [
    "## 10-Fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "147bf8ed-7a1a-4eec-94e0-31a263b52c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1NN:\n",
      "  Accuracy:          0.9530 (+/- 0.0147)\n",
      "  Balanced Accuracy: 0.3717 (+/- 0.0502)\n",
      "  Precision:         0.9608 (+/- 0.0049)\n",
      "  Recall:            0.9530 (+/- 0.0147)\n",
      "  F1-Score:          0.9547 (+/- 0.0089)\n",
      "  ROC-AUC:           0.6583 (+/- 0.0325)\n",
      "\n",
      "3NN:\n",
      "  Accuracy:          0.9657 (+/- 0.0097)\n",
      "  Balanced Accuracy: 0.2886 (+/- 0.0410)\n",
      "  Precision:         0.9575 (+/- 0.0085)\n",
      "  Recall:            0.9657 (+/- 0.0097)\n",
      "  F1-Score:          0.9580 (+/- 0.0071)\n",
      "  ROC-AUC:           0.7495 (+/- 0.0503)\n",
      "\n",
      "5NN:\n",
      "  Accuracy:          0.9683 (+/- 0.0050)\n",
      "  Balanced Accuracy: 0.2595 (+/- 0.0255)\n",
      "  Precision:         0.9521 (+/- 0.0053)\n",
      "  Recall:            0.9683 (+/- 0.0050)\n",
      "  F1-Score:          0.9579 (+/- 0.0035)\n",
      "  ROC-AUC:           0.7996 (+/- 0.0424)\n",
      "\n",
      "7NN:\n",
      "  Accuracy:          0.9693 (+/- 0.0037)\n",
      "  Balanced Accuracy: 0.2500 (+/- 0.0256)\n",
      "  Precision:         0.9524 (+/- 0.0057)\n",
      "  Recall:            0.9693 (+/- 0.0037)\n",
      "  F1-Score:          0.9581 (+/- 0.0030)\n",
      "  ROC-AUC:           0.8136 (+/- 0.0427)\n",
      "\n",
      "9NN:\n",
      "  Accuracy:          0.9691 (+/- 0.0038)\n",
      "  Balanced Accuracy: 0.2349 (+/- 0.0266)\n",
      "  Precision:         0.9492 (+/- 0.0065)\n",
      "  Recall:            0.9691 (+/- 0.0038)\n",
      "  F1-Score:          0.9570 (+/- 0.0034)\n",
      "  ROC-AUC:           0.8262 (+/- 0.0396)\n",
      "\n",
      "Naive Bayes:\n",
      "  Accuracy:          0.9536 (+/- 0.0234)\n",
      "  Balanced Accuracy: 0.4078 (+/- 0.0544)\n",
      "  Precision:         0.9595 (+/- 0.0058)\n",
      "  Recall:            0.9536 (+/- 0.0234)\n",
      "  F1-Score:          0.9542 (+/- 0.0147)\n",
      "  ROC-AUC:           0.9283 (+/- 0.0318)\n",
      "      Model  Accuracy  Balanced Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "        1NN  0.952990           0.371716   0.960760 0.952990  0.954718 0.658337\n",
      "        3NN  0.965720           0.288613   0.957496 0.965720  0.958005 0.749480\n",
      "        5NN  0.968325           0.259547   0.952126 0.968325  0.957899 0.799622\n",
      "        7NN  0.969327           0.249958   0.952392 0.969327  0.958094 0.813636\n",
      "        9NN  0.969127           0.234948   0.949216 0.969127  0.957044 0.826204\n",
      "Naive Bayes  0.953594           0.407825   0.959456 0.953594  0.954213 0.928296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'balanced_accuracy': 'balanced_accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average='weighted', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average='weighted', zero_division=0),\n",
    "    'roc_auc': 'roc_auc_ovr_weighted'\n",
    "}\n",
    "\n",
    "results_cv = []\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        cv_results = cross_validate(model, X_m, y_m, cv=10, scoring=scoring, \n",
    "                                    error_score='raise')\n",
    "        \n",
    "        metrics = {\n",
    "            'Model': name,\n",
    "            'Accuracy': cv_results['test_accuracy'].mean(),\n",
    "            'Accuracy_std': cv_results['test_accuracy'].std(),\n",
    "            'Balanced Accuracy': cv_results['test_balanced_accuracy'].mean(),\n",
    "            'Balanced Accuracy_std': cv_results['test_balanced_accuracy'].std(),\n",
    "            'Precision': cv_results['test_precision'].mean(),\n",
    "            'Precision_std': cv_results['test_precision'].std(),\n",
    "            'Recall': cv_results['test_recall'].mean(),\n",
    "            'Recall_std': cv_results['test_recall'].std(),\n",
    "            'F1-Score': cv_results['test_f1'].mean(),\n",
    "            'F1-Score_std': cv_results['test_f1'].std(),\n",
    "            'ROC-AUC': cv_results['test_roc_auc'].mean(),\n",
    "            'ROC-AUC_std': cv_results['test_roc_auc'].std()\n",
    "        }\n",
    "        results_cv.append(metrics)\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Accuracy:          {metrics['Accuracy']:.4f} (+/- {metrics['Accuracy_std']:.4f})\")\n",
    "        print(f\"  Balanced Accuracy: {metrics['Balanced Accuracy']:.4f} (+/- {metrics['Balanced Accuracy_std']:.4f})\")\n",
    "        print(f\"  Precision:         {metrics['Precision']:.4f} (+/- {metrics['Precision_std']:.4f})\")\n",
    "        print(f\"  Recall:            {metrics['Recall']:.4f} (+/- {metrics['Recall_std']:.4f})\")\n",
    "        print(f\"  F1-Score:          {metrics['F1-Score']:.4f} (+/- {metrics['F1-Score_std']:.4f})\")\n",
    "        print(f\"  ROC-AUC:           {metrics['ROC-AUC']:.4f} (+/- {metrics['ROC-AUC_std']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {str(e)}\")\n",
    "\n",
    "df_cv = pd.DataFrame(results_cv)\n",
    "print(df_cv[['Model', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18659985-ccd6-4f73-9ef7-7fcd13fd8294",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "**Se confirma la tendencia de los valores de K para NN**\n",
    "**Naive Bayes muy superior a todo lo demás en ROC-AUC**\n",
    "\n",
    "**Modelos K altos consistentes entre los folds (+-0.0..37)**\n",
    "**Naive Bayes presenta muy alta varianza entre los folds (+-0.0234)**\n",
    "\n",
    "**Todas las métricas fueron ligeramente superiores en hold out**\n",
    "**Los folds evidencían aún más la inestabilidad de K bajos en NN**\n",
    "\n",
    "**Mejor modelo 7NN**\n",
    "- 96.93% acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e683f-0a92-4e3a-94bc-0af73efee052",
   "metadata": {},
   "source": [
    "## Leave one out (LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2d8537e-8c4c-4dc2-8122-95c23baf87e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAVE-ONE-OUT\n",
      "\n",
      "Evaluando 1NN...\n",
      "  Accuracy: 0.9662 (+/- 0.1807)\n",
      "\n",
      "Evaluando 3NN...\n",
      "  Accuracy: 0.9724 (+/- 0.1637)\n",
      "\n",
      "Evaluando 5NN...\n",
      "  Accuracy: 0.9716 (+/- 0.1660)\n",
      "\n",
      "Evaluando 7NN...\n",
      "  Accuracy: 0.9716 (+/- 0.1660)\n",
      "\n",
      "Evaluando 9NN...\n",
      "  Accuracy: 0.9704 (+/- 0.1694)\n",
      "\n",
      "Evaluando Naive Bayes...\n",
      "  Accuracy: 0.9583 (+/- 0.1999)\n",
      "\n",
      "================================================================================\n",
      "RESUMEN LEAVE-ONE-OUT\n",
      "      Model  Accuracy  Accuracy_std\n",
      "        1NN  0.966219      0.180665\n",
      "        3NN  0.972434      0.163726\n",
      "        5NN  0.971632      0.166022\n",
      "        7NN  0.971632      0.166022\n",
      "        9NN  0.970429      0.169400\n",
      "Naive Bayes  0.958300      0.199903\n",
      "      Model  Hold-Out  10-Fold CV      LOO\n",
      "        1NN  0.964250    0.952990 0.966219\n",
      "        3NN  0.970932    0.965720 0.972434\n",
      "        5NN  0.972603    0.968325 0.971632\n",
      "        7NN  0.971266    0.969327 0.971632\n",
      "        9NN  0.970264    0.969127 0.970429\n",
      "Naive Bayes  0.961577    0.953594 0.958300\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "results_loo = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluando {name}...\")\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_m, y_m, cv=loo, scoring='accuracy')\n",
    "        \n",
    "        metrics = {\n",
    "            'Model': name,\n",
    "            'Accuracy': scores.mean(),\n",
    "            'Accuracy_std': scores.std()\n",
    "        }\n",
    "        results_loo.append(metrics)\n",
    "        \n",
    "        print(f\"  Accuracy: {metrics['Accuracy']:.4f} (+/- {metrics['Accuracy_std']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "\n",
    "df_loo = pd.DataFrame(results_loo)\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"RESUMEN LEAVE-ONE-OUT\")\n",
    "print(df_loo.to_string(index=False))\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Model': [m['Model'] for m in results_holdout],\n",
    "    'Hold-Out': [m['Accuracy'] for m in results_holdout],\n",
    "    '10-Fold CV': [m['Accuracy'] for m in results_cv],\n",
    "    'LOO': [m['Accuracy'] for m in results_loo]\n",
    "})\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec28bb1-bc41-4a1a-b5ef-3e6d7ba6c4b2",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "**Desviaciones estandar muy altas**\n",
    "**Mejor modelo 3NN**\n",
    "- Baja inestabilidad\n",
    "- Alata accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7287516-9ab1-46ae-88f7-7e99200b4303",
   "metadata": {},
   "source": [
    "## Particle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ccd418e-5833-4248-8db5-3bffa27736bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_particle_filepath = './datasets/particle/X_particleDataset.joblib'\n",
    "y_particle_filepath = './datasets/particle/y_particleDataset.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b57755-59aa-4fe8-875d-c388b9edb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p = load(X_particle_filepath)\n",
    "y_p = load(y_particle_filepath).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5d0d0e-dca1-4af6-bbe1-bb14bac65db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250000 entries, 0 to 249999\n",
      "Data columns (total 30 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   DER_mass_MMC                 250000 non-null  float64\n",
      " 1   DER_mass_transverse_met_lep  250000 non-null  float64\n",
      " 2   DER_mass_vis                 250000 non-null  float64\n",
      " 3   DER_pt_h                     250000 non-null  float64\n",
      " 4   DER_deltaeta_jet_jet         250000 non-null  float64\n",
      " 5   DER_mass_jet_jet             250000 non-null  float64\n",
      " 6   DER_prodeta_jet_jet          250000 non-null  float64\n",
      " 7   DER_deltar_tau_lep           250000 non-null  float64\n",
      " 8   DER_pt_tot                   250000 non-null  float64\n",
      " 9   DER_sum_pt                   250000 non-null  float64\n",
      " 10  DER_pt_ratio_lep_tau         250000 non-null  float64\n",
      " 11  DER_met_phi_centrality       250000 non-null  float64\n",
      " 12  DER_lep_eta_centrality       250000 non-null  float64\n",
      " 13  PRI_tau_pt                   250000 non-null  float64\n",
      " 14  PRI_tau_eta                  250000 non-null  float64\n",
      " 15  PRI_tau_phi                  250000 non-null  float64\n",
      " 16  PRI_lep_pt                   250000 non-null  float64\n",
      " 17  PRI_lep_eta                  250000 non-null  float64\n",
      " 18  PRI_lep_phi                  250000 non-null  float64\n",
      " 19  PRI_met                      250000 non-null  float64\n",
      " 20  PRI_met_phi                  250000 non-null  float64\n",
      " 21  PRI_met_sumet                250000 non-null  float64\n",
      " 22  PRI_jet_num                  250000 non-null  float64\n",
      " 23  PRI_jet_leading_pt           250000 non-null  float64\n",
      " 24  PRI_jet_leading_eta          250000 non-null  float64\n",
      " 25  PRI_jet_leading_phi          250000 non-null  float64\n",
      " 26  PRI_jet_subleading_pt        250000 non-null  float64\n",
      " 27  PRI_jet_subleading_eta       250000 non-null  float64\n",
      " 28  PRI_jet_subleading_phi       250000 non-null  float64\n",
      " 29  PRI_jet_all_pt               250000 non-null  float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 57.2 MB\n",
      "None\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_p.info())\n",
    "print(y_p.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d2a13-914d-4025-971d-69de92c833e4",
   "metadata": {},
   "source": [
    "## HOLD-OUT 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16012d9e-f8ce-49d1-9a39-2985320426ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1NN:\n",
      "  Accuracy:          0.7402\n",
      "  Balanced Accuracy: 0.7163\n",
      "  Precision:         0.7427\n",
      "  Recall:            0.7402\n",
      "  F1-Score:          0.7414\n",
      "  MCC:               0.4288\n",
      "  Cohen Kappa:       0.4286\n",
      "  ROC-AUC:           0.7163\n",
      "  Confusion Matrix:\n",
      "[[39066 10234]\n",
      " [ 9249 16451]]\n",
      "\n",
      "3NN:\n",
      "  Accuracy:          0.7725\n",
      "  Balanced Accuracy: 0.7467\n",
      "  Precision:         0.7721\n",
      "  Recall:            0.7725\n",
      "  F1-Score:          0.7723\n",
      "  MCC:               0.4942\n",
      "  Cohen Kappa:       0.4942\n",
      "  ROC-AUC:           0.8084\n",
      "  Confusion Matrix:\n",
      "[[40855  8445]\n",
      " [ 8618 17082]]\n",
      "\n",
      "5NN:\n",
      "  Accuracy:          0.7856\n",
      "  Balanced Accuracy: 0.7592\n",
      "  Precision:         0.7845\n",
      "  Recall:            0.7856\n",
      "  F1-Score:          0.7850\n",
      "  MCC:               0.5215\n",
      "  Cohen Kappa:       0.5215\n",
      "  ROC-AUC:           0.8358\n",
      "  Confusion Matrix:\n",
      "[[41566  7734]\n",
      " [ 8343 17357]]\n",
      "\n",
      "7NN:\n",
      "  Accuracy:          0.7915\n",
      "  Balanced Accuracy: 0.7641\n",
      "  Precision:         0.7898\n",
      "  Recall:            0.7915\n",
      "  F1-Score:          0.7906\n",
      "  MCC:               0.5333\n",
      "  Cohen Kappa:       0.5330\n",
      "  ROC-AUC:           0.8481\n",
      "  Confusion Matrix:\n",
      "[[41971  7329]\n",
      " [ 8305 17395]]\n",
      "\n",
      "9NN:\n",
      "  Accuracy:          0.7955\n",
      "  Balanced Accuracy: 0.7678\n",
      "  Precision:         0.7936\n",
      "  Recall:            0.7955\n",
      "  F1-Score:          0.7944\n",
      "  MCC:               0.5415\n",
      "  Cohen Kappa:       0.5412\n",
      "  ROC-AUC:           0.8553\n",
      "  Confusion Matrix:\n",
      "[[42197  7103]\n",
      " [ 8234 17466]]\n",
      "\n",
      "Naive Bayes:\n",
      "  Accuracy:          0.6862\n",
      "  Balanced Accuracy: 0.6207\n",
      "  Precision:         0.6708\n",
      "  Recall:            0.6862\n",
      "  F1-Score:          0.6728\n",
      "  MCC:               0.2633\n",
      "  Cohen Kappa:       0.2574\n",
      "  ROC-AUC:           0.7652\n",
      "  Confusion Matrix:\n",
      "[[40861  8439]\n",
      " [15096 10604]]\n",
      " Accuracy  Balanced Accuracy  Precision   Recall  F1-Score      MCC  Cohen Kappa  ROC-AUC       Model\n",
      " 0.740227           0.716265   0.742749 0.740227  0.741358 0.428778     0.428599 0.716265         1NN\n",
      " 0.772493           0.746686   0.772132 0.772493  0.772308 0.494174     0.494167 0.808446         3NN\n",
      " 0.785640           0.759247   0.784494 0.785640  0.785013 0.521537     0.521451 0.835837         5NN\n",
      " 0.791547           0.764093   0.789839 0.791547  0.790551 0.533259     0.533032 0.848140         7NN\n",
      " 0.795507           0.767767   0.793609 0.795507  0.794366 0.541545     0.541235 0.855273         9NN\n",
      " 0.686200           0.620715   0.670811 0.686200  0.672779 0.263261     0.257388 0.765245 Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p, y_p, test_size=0.3, \n",
    "                                                    random_state=42, stratify=y_p)\n",
    "\n",
    "results_holdout = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_p_train, y_p_train)\n",
    "    y_p_pred = model.predict(X_p_test)\n",
    "    y_p_proba = model.predict_proba(X_p_test) if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    metrics = evaluate_model(y_p_test, y_p_pred, y_p_proba)\n",
    "    metrics['Model'] = name\n",
    "    results_holdout.append(metrics)\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy:          {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"  Balanced Accuracy: {metrics['Balanced Accuracy']:.4f}\")\n",
    "    print(f\"  Precision:         {metrics['Precision']:.4f}\")\n",
    "    print(f\"  Recall:            {metrics['Recall']:.4f}\")\n",
    "    print(f\"  F1-Score:          {metrics['F1-Score']:.4f}\")\n",
    "    print(f\"  MCC:               {metrics['MCC']:.4f}\")\n",
    "    print(f\"  Cohen Kappa:       {metrics['Cohen Kappa']:.4f}\")\n",
    "    if 'ROC-AUC' in metrics and not np.isnan(metrics['ROC-AUC']):\n",
    "        print(f\"  ROC-AUC:           {metrics['ROC-AUC']:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_p_test, y_p_pred)\n",
    "    print(f\"  Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "df_holdout = pd.DataFrame(results_holdout)\n",
    "print(df_holdout.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0b819-c147-4273-94c6-2ce15c4b90bb",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "\n",
    "**Mejor modelo: 9NN**\n",
    "- 79.55% acc\n",
    "- 76.77% balanced acc\n",
    "- 0.85% ROC-AUC\n",
    "\n",
    "**Naive bayes no resalta tanto debido a que el desbalance no es tan amplio y solo hay dos clases**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89063f2-7911-4ee8-bf70-72ba66505454",
   "metadata": {},
   "source": [
    "## 10-Fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac973522-6343-49c0-b6ab-7296c56194d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1NN:\n",
      "  Accuracy:          0.7423 (+/- 0.0033)\n",
      "  Balanced Accuracy: 0.7187 (+/- 0.0036)\n",
      "  Precision:         0.7449 (+/- 0.0032)\n",
      "  Recall:            0.7423 (+/- 0.0033)\n",
      "  F1-Score:          0.7435 (+/- 0.0032)\n",
      "  ROC-AUC:           0.7187 (+/- 0.0036)\n",
      "\n",
      "3NN:\n",
      "  Accuracy:          0.7748 (+/- 0.0020)\n",
      "  Balanced Accuracy: 0.7489 (+/- 0.0026)\n",
      "  Precision:         0.7743 (+/- 0.0021)\n",
      "  Recall:            0.7748 (+/- 0.0020)\n",
      "  F1-Score:          0.7745 (+/- 0.0020)\n",
      "  ROC-AUC:           0.8114 (+/- 0.0021)\n",
      "\n",
      "5NN:\n",
      "  Accuracy:          0.7876 (+/- 0.0022)\n",
      "  Balanced Accuracy: 0.7612 (+/- 0.0030)\n",
      "  Precision:         0.7864 (+/- 0.0024)\n",
      "  Recall:            0.7876 (+/- 0.0022)\n",
      "  F1-Score:          0.7869 (+/- 0.0023)\n",
      "  ROC-AUC:           0.8382 (+/- 0.0023)\n",
      "\n",
      "7NN:\n",
      "  Accuracy:          0.7936 (+/- 0.0024)\n",
      "  Balanced Accuracy: 0.7667 (+/- 0.0032)\n",
      "  Precision:         0.7920 (+/- 0.0026)\n",
      "  Recall:            0.7936 (+/- 0.0024)\n",
      "  F1-Score:          0.7927 (+/- 0.0025)\n",
      "  ROC-AUC:           0.8508 (+/- 0.0021)\n",
      "\n",
      "9NN:\n",
      "  Accuracy:          0.7976 (+/- 0.0022)\n",
      "  Balanced Accuracy: 0.7703 (+/- 0.0032)\n",
      "  Precision:         0.7958 (+/- 0.0024)\n",
      "  Recall:            0.7976 (+/- 0.0022)\n",
      "  F1-Score:          0.7965 (+/- 0.0024)\n",
      "  ROC-AUC:           0.8582 (+/- 0.0021)\n",
      "\n",
      "Naive Bayes:\n",
      "  Accuracy:          0.6840 (+/- 0.0028)\n",
      "  Balanced Accuracy: 0.6190 (+/- 0.0038)\n",
      "  Precision:         0.6687 (+/- 0.0033)\n",
      "  Recall:            0.6840 (+/- 0.0028)\n",
      "  F1-Score:          0.6709 (+/- 0.0032)\n",
      "  ROC-AUC:           0.7631 (+/- 0.0027)\n",
      "      Model  Accuracy  Balanced Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "        1NN  0.742324           0.718669   0.744884 0.742324  0.743461 0.718669\n",
      "        3NN  0.774780           0.748894   0.774289 0.774780  0.774518 0.811447\n",
      "        5NN  0.787584           0.761159   0.786366 0.787584  0.786903 0.838159\n",
      "        7NN  0.793584           0.766695   0.792018 0.793584  0.792671 0.850840\n",
      "        9NN  0.797580           0.770327   0.795794 0.797580  0.796505 0.858158\n",
      "Naive Bayes  0.684016           0.619030   0.668651 0.684016  0.670910 0.763117\n"
     ]
    }
   ],
   "source": [
    "results_cv = []\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        cv_results = cross_validate(model, X_p, y_p, cv=10, scoring=scoring, \n",
    "                                    error_score='raise')\n",
    "        \n",
    "        metrics = {\n",
    "            'Model': name,\n",
    "            'Accuracy': cv_results['test_accuracy'].mean(),\n",
    "            'Accuracy_std': cv_results['test_accuracy'].std(),\n",
    "            'Balanced Accuracy': cv_results['test_balanced_accuracy'].mean(),\n",
    "            'Balanced Accuracy_std': cv_results['test_balanced_accuracy'].std(),\n",
    "            'Precision': cv_results['test_precision'].mean(),\n",
    "            'Precision_std': cv_results['test_precision'].std(),\n",
    "            'Recall': cv_results['test_recall'].mean(),\n",
    "            'Recall_std': cv_results['test_recall'].std(),\n",
    "            'F1-Score': cv_results['test_f1'].mean(),\n",
    "            'F1-Score_std': cv_results['test_f1'].std(),\n",
    "            'ROC-AUC': cv_results['test_roc_auc'].mean(),\n",
    "            'ROC-AUC_std': cv_results['test_roc_auc'].std()\n",
    "        }\n",
    "        results_cv.append(metrics)\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Accuracy:          {metrics['Accuracy']:.4f} (+/- {metrics['Accuracy_std']:.4f})\")\n",
    "        print(f\"  Balanced Accuracy: {metrics['Balanced Accuracy']:.4f} (+/- {metrics['Balanced Accuracy_std']:.4f})\")\n",
    "        print(f\"  Precision:         {metrics['Precision']:.4f} (+/- {metrics['Precision_std']:.4f})\")\n",
    "        print(f\"  Recall:            {metrics['Recall']:.4f} (+/- {metrics['Recall_std']:.4f})\")\n",
    "        print(f\"  F1-Score:          {metrics['F1-Score']:.4f} (+/- {metrics['F1-Score_std']:.4f})\")\n",
    "        print(f\"  ROC-AUC:           {metrics['ROC-AUC']:.4f} (+/- {metrics['ROC-AUC_std']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {str(e)}\")\n",
    "\n",
    "df_cv = pd.DataFrame(results_cv)\n",
    "print(df_cv[['Model', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20727ac7-8f1d-4ea7-9cd8-51f1c5ef8c21",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "**Mejor modelo confirmado: 9NN**\n",
    "- 79.75% acc\n",
    "- 77.03% balanced acc\n",
    "- 0.8581 ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33beff91-017c-4471-aebb-8d4e007500a8",
   "metadata": {},
   "source": [
    "## Leave one out (LOO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1217185-7401-444d-93f5-169aa330ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando 1NN...\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "results_loo = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluando {name}...\")\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_p, y_p, cv=loo, scoring='accuracy')\n",
    "        \n",
    "        metrics = {\n",
    "            'Model': name,\n",
    "            'Accuracy': scores.mean(),\n",
    "            'Accuracy_std': scores.std()\n",
    "        }\n",
    "        results_loo.append(metrics)\n",
    "        \n",
    "        print(f\"  Accuracy: {metrics['Accuracy']:.4f} (+/- {metrics['Accuracy_std']:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "\n",
    "df_loo = pd.DataFrame(results_loo)\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"RESUMEN LEAVE-ONE-OUT\")\n",
    "print(df_loo.to_string(index=False))\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Model': [m['Model'] for m in results_holdout],\n",
    "    'Hold-Out': [m['Accuracy'] for m in results_holdout],\n",
    "    '10-Fold CV': [m['Accuracy'] for m in results_cv],\n",
    "    'LOO': [m['Accuracy'] for m in results_loo]\n",
    "})\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a0d19-7c95-4a8d-96ea-9ad8e56b3acc",
   "metadata": {},
   "source": [
    "## Observaciones\n",
    "Debido al tamaño del dataset, no es viable aplicar leave one out (>7 horas de intento de ejecución)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3003bb6-051d-4b4b-bb1d-11ac9d7f3537",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "Utilizar clasifiadores básicos como Bayesiano y KNN tiene sus ventajas y también sus limitacioens. Dependeindo de la dimensionalidad, volumen y cercanía geometrica de las características de cada una de las clases es posbile que utilizar estos métodos de clasifiación mediante aprendizaje máquina sean efectivos, sin embargo, son muy propensos a verse afectados por cuestiones como desbalance de clases, alta varianza, outliers. Etc. Como se observó en el primer dataset, la métrica de precisión individualmente puede ser engañosa, por lo que vale la pena tomar en cuenta alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5a339-bfe7-48fd-95ca-26bf2aa33149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
